{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Иерархические модели: Результаты экспериментов\n",
    "\n",
    "## Описание эндпоинтов\n",
    "1. **Категория EPA** (классы 1-4)  \n",
    "2. **Категория GHS** (классы 1-5)  \n",
    "3. **LD50** (регрессия, ммоль/кг)  \n",
    "4. **Токсичность** (бинарная классификация: `1`, если LD50 < 2000 мг/кг)  \n",
    "5. **Высокая токсичность** (бинарная классификация: `1`, если LD50 < 50 мг/кг)  \n",
    "\n",
    "## Используемые алгоритмы\n",
    "- **Random Forest**  \n",
    "- **SVM/SVR**  \n",
    "- **XGBoost**  \n",
    "- **kNN**  \n",
    "\n",
    "Все модели настроены с использованием **5-кратной кросс-валидации**.\n",
    "\n",
    "---\n",
    "\n",
    "### Эндпоинт 1: Токсичность (LD50 < 2000 мг/кг)\n",
    "**Тип задачи**: Бинарная классификация  \n",
    "\n",
    "| Алгоритм       | Оптимальные гиперпараметры                                                                                     | Best Score       |\n",
    "|----------------|---------------------------------------------------------------------------------------------------------------|------------------|\n",
    "| **kNN**        | `n_neighbors=151`, `p=1`, `weights='distance'`                                                                | 0.8786442988615353 |\n",
    "| **SVM**        | `C=10`, `gamma=0.001`, `kernel='rbf'`                                                                         | 0.8816975779192351 |\n",
    "| **Random Forest** | `n_estimators=500`, `min_samples_split=10`, `min_samples_leaf=6`, `max_features='log2'`, `max_depth=65`, `bootstrap=True` | 0.8814752606339683 |\n",
    "| **XGBoost**    | `subsample=0.6`, `n_estimators=500`, `min_child_weight=1`, `max_depth=3`, `learning_rate=0.01`, `gamma=5`, `colsample_bytree=0.6` | 0.8817171651619816 |\n",
    "\n",
    "---\n",
    "\n",
    "### Эндпоинт 2: Прогнозирование LD50 (регрессия)\n",
    "**Тип задачи**: Регрессия  \n",
    "\n",
    "| Алгоритм       | Оптимальные гиперпараметры                                                                                     | Best Score       |\n",
    "|----------------|---------------------------------------------------------------------------------------------------------------|------------------|\n",
    "| **Random Forest** | `n_estimators=1500`, `min_samples_split=5`, `min_samples_leaf=4`, `max_features='sqrt'`, `max_depth=80`, `bootstrap=False` | 0.3066968307723924 |\n",
    "| **XGBoost**    | `subsample=0.6`, `n_estimators=1500`, `min_child_weight=1`, `max_depth=10`, `learning_rate=0.01`, `gamma=1`, `colsample_bytree=0.9` | 0.3072981768556339 |\n",
    "| **SVR**        | `C=1`, `gamma=0.01`, `kernel='rbf'`                                                                           | 0.30772790955034346 |\n",
    "| **kNN**        | `n_neighbors=45`, `p=2`, `weights='distance'`                                                                 | 0.3181178447216808 |\n",
    "\n",
    "---\n",
    "\n",
    "### Эндпоинт 3: Категория GHS (многоклассовая классификация)\n",
    "**Тип задачи**: Многоклассовая классификация (5 классов)  \n",
    "\n",
    "| Алгоритм       | Оптимальные гиперпараметры                                                                                     | Best Score       |\n",
    "|----------------|---------------------------------------------------------------------------------------------------------------|------------------|\n",
    "| **Random Forest** | `n_estimators=500`, `min_samples_split=2`, `min_samples_leaf=2`, `max_features='sqrt'`, `max_depth=65`, `bootstrap=False` | 0.6389376458324004 |\n",
    "| **XGBoost**    | `subsample=0.9`, `n_estimators=500`, `min_child_weight=3`, `max_depth=10`, `learning_rate=0.01`, `gamma=0`, `colsample_bytree=0.6` | 0.6362382063966948 |\n",
    "| **SVM**        | `C=0.1`, `kernel='linear'`                                                                                    | 0.6338661563414092 |\n",
    "| **kNN**        | `n_neighbors=55`, `p=1`, `weights='distance'`                                                                 | 0.6290994018747665 |\n",
    "\n",
    "---\n",
    "\n",
    "**Примечание**:  \n",
    "- Значения `Best Score` приведены без округления.  \n",
    "- Для регрессии (LD50) метрика — коэффициент детерминации (R²).  \n",
    "- Для классификации — точность (Accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import * \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import itertools\n",
    "from pprint import pprint\n",
    "import joblib\n",
    "\n",
    "import statistics\n",
    "\n",
    "# Models\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "from sklearn.model_selection import KFold, cross_validate, GridSearchCV, cross_val_score, RandomizedSearchCV \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "#regression matrics\n",
    "from sklearn.metrics import mean_absolute_error , mean_squared_error, r2_score\n",
    "\n",
    "#classification metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, roc_auc_score, f1_score, matthews_corrcoef\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection._split import check_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8221, 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = pd.read_csv('../data/processed/train_labels.csv', index_col = 'CASRN')\n",
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8221, 100)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Hfeatures = pd.read_csv('../data/Hmodel_features_combined/train_Hfeatures.csv', index_col = 'CASRN')\n",
    "train_Hfeatures.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Endpoint 1: Toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.798 std: 0.014\n",
      "Balance Accuracy: 0.792 std: 0.014\n",
      "matthews_corrcoef: 0.588 std: 0.028\n",
      "f1_score: 0.798 std: 0.014\n",
      "AUROC: 0.792 std: 0.014\n",
      "CPU times: total: 5min 50s\n",
      "Wall time: 1min 4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../results/Hierarchical_models/Toxic_RF_Hmodel_CVScore']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#yes\n",
    "endpoint = 'Toxic'\n",
    "descriptor = 'Hmodel'\n",
    "algorithm = 'RF'\n",
    "name = f'{endpoint}_{algorithm}_{descriptor}'\n",
    "\n",
    "encoder_toxic = joblib.load('../encoder_models/encoder_toxic.joblib')\n",
    "\n",
    "# model\n",
    "rf_clf = RandomForestClassifier(random_state =42, n_jobs=6,\n",
    "                              n_estimators = 500, min_samples_split = 10, min_samples_leaf=6,\n",
    "                              max_features = 'log2', max_depth=65, bootstrap= True)\n",
    "\n",
    "#input\n",
    "a, b,c,d,e = prepare_input(train_labels, train_Hfeatures, target = 'toxic', encoder = encoder_toxic)\n",
    "\n",
    "# results\n",
    "BCM_mf,  BCM_oof, BCM_base_model, cv_score  = Classification_meta_features(rf_clf, a, c, b, d, e,cv=10,n_jobs=1, \n",
    "                                                      col_names = [f'{name}-0', f'{name}-1'])\n",
    "# report the results\n",
    "report_clf_models(cv_score)\n",
    "\n",
    "# Save results\n",
    "# BCM_mf.to_csv(f'../data/Hmodel_features/{name}.csv') # no need for this \n",
    "np.save(f'../results/Hierarchical_models/{name}.npy', BCM_oof)\n",
    "joblib.dump(BCM_base_model, f'../models/Hierarchical_models/{name}.pkl')\n",
    "joblib.dump(cv_score, f'../results/Hierarchical_models/{name}_CVScore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.799 std: 0.016\n",
      "Balance Accuracy: 0.792 std: 0.016\n",
      "matthews_corrcoef: 0.589 std: 0.032\n",
      "f1_score: 0.798 std: 0.016\n",
      "AUROC: 0.792 std: 0.016\n",
      "CPU times: total: 14.3 s\n",
      "Wall time: 2min 13s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../results/Hierarchical_models/Toxic_SVM_Hmodel_CVScore']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#yes\n",
    "endpoint = 'Toxic'\n",
    "descriptor = 'Hmodel'\n",
    "algorithm = 'SVM'\n",
    "name = f'{endpoint}_{algorithm}_{descriptor}'\n",
    "\n",
    "encoder_toxic = joblib.load('../encoder_models/encoder_toxic.joblib')\n",
    "\n",
    "# model\n",
    "clf = SVC(random_state=42, probability=True,\n",
    "          C = 10, gamma = 0.001, kernel = 'rbf')\n",
    "\n",
    "#input\n",
    "a, b,c,d,e = prepare_input(train_labels, train_Hfeatures, target = 'toxic', encoder = encoder_toxic)\n",
    "\n",
    "# results\n",
    "BCM_mf,  BCM_oof, BCM_model, cv_score  = Classification_meta_features(clf, a, c, b, d, e,cv=10,n_jobs=6, \n",
    "                                                      col_names = [f'{name}-0', f'{name}-1'])\n",
    "# report the results\n",
    "report_clf_models(cv_score)\n",
    "\n",
    "# Save results\n",
    "# BCM_mf.to_csv(f'../data/Hmodel_features/{name}.csv') # no need for this \n",
    "np.save(f'../results/Hierarchical_models/{name}.npy', BCM_oof)\n",
    "joblib.dump(BCM_model, f'../models/Hierarchical_models/{name}.pkl')\n",
    "joblib.dump(cv_score, f'../results/Hierarchical_models/{name}_CVScore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8 std: 0.013\n",
      "Balance Accuracy: 0.794 std: 0.013\n",
      "matthews_corrcoef: 0.592 std: 0.027\n",
      "f1_score: 0.8 std: 0.013\n",
      "AUROC: 0.794 std: 0.013\n",
      "CPU times: total: 1min 43s\n",
      "Wall time: 17.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../results/Hierarchical_models/Toxic_xgboost_Hmodel_CVScore']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#yes\n",
    "endpoint = 'Toxic'\n",
    "descriptor = 'Hmodel'\n",
    "algorithm = 'xgboost'\n",
    "name = f'{endpoint}_{algorithm}_{descriptor}'\n",
    "\n",
    "encoder_toxic = joblib.load('../encoder_models/encoder_toxic.joblib')\n",
    "\n",
    "# model\n",
    "clf = XGBClassifier(random_state =123, n_jobs=6,\n",
    "                    subsample = 0.6, n_estimators = 500, min_child_weight=1,\n",
    "                    max_depth = 3, learning_rate=0.01, gamma= 5,\n",
    "                    colsample_bytree = 0.6)\n",
    "\n",
    "\n",
    "#input\n",
    "a, b,c,d,e = prepare_input(train_labels, train_Hfeatures, target = 'toxic', encoder = encoder_toxic)\n",
    "\n",
    "# results\n",
    "BCM_mf,  BCM_oof, BCM_model, cv_score  = Classification_meta_features(clf, a, c, b, d, e,cv=10,n_jobs=1, \n",
    "                                                      col_names = [f'{name}-0', f'{name}-1'])\n",
    "# report the results\n",
    "report_clf_models(cv_score)\n",
    "\n",
    "# Save results\n",
    "# BCM_mf.to_csv(f'../data/Hmodel_features/{name}.csv') # no need for this \n",
    "np.save(f'../results/Hierarchical_models/{name}.npy', BCM_oof)\n",
    "joblib.dump(BCM_model, f'../models/Hierarchical_models/{name}.pkl')\n",
    "joblib.dump(cv_score, f'../results/Hierarchical_models/{name}_CVScore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.794 std: 0.016\n",
      "Balance Accuracy: 0.788 std: 0.016\n",
      "matthews_corrcoef: 0.58 std: 0.033\n",
      "f1_score: 0.794 std: 0.016\n",
      "AUROC: 0.788 std: 0.016\n",
      "CPU times: total: 1.42 s\n",
      "Wall time: 2.48 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../results/Hierarchical_models/Toxic_knn_Hmodel_CVScore']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#yes\n",
    "endpoint = 'Toxic'\n",
    "descriptor = 'Hmodel'\n",
    "algorithm = 'knn'\n",
    "name = f'{endpoint}_{algorithm}_{descriptor}'\n",
    "\n",
    "encoder_toxic = joblib.load('../encoder_models/encoder_toxic.joblib')\n",
    "\n",
    "# model\n",
    "clf = KNeighborsClassifier(n_neighbors = 151, p=1, weights = 'distance')\n",
    "\n",
    "#input\n",
    "a, b,c,d,e = prepare_input(train_labels, train_Hfeatures, target = 'toxic', encoder = encoder_toxic)\n",
    "\n",
    "# results\n",
    "BCM_mf,  BCM_oof, BCM_model, cv_score  = Classification_meta_features(clf, a, c, b, d, e,cv=10,n_jobs=6, \n",
    "                                                      col_names = [f'{name}-0', f'{name}-1'])\n",
    "# report the results\n",
    "report_clf_models(cv_score)\n",
    "\n",
    "# Save results\n",
    "# BCM_mf.to_csv(f'../data/Hmodel_features/{name}.csv') # no need for this \n",
    "np.save(f'../results/Hierarchical_models/{name}.npy', BCM_oof)\n",
    "joblib.dump(BCM_model, f'../models/Hierarchical_models/{name}.pkl')\n",
    "joblib.dump(cv_score, f'../results/Hierarchical_models/{name}_CVScore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Endpoint 2: EPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.659 std: 0.014\n",
      "Balance Accuracy: 0.588 std: 0.018\n",
      "matthews_corrcoef: 0.458 std: 0.023\n",
      "f1_score: 0.648 std: 0.016\n",
      "AUROC: 0.708 std: 0.012\n",
      "CPU times: total: 20min 31s\n",
      "Wall time: 3min 32s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../results/Hierarchical_models/EPA_RF_Hmodel_CVScore']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#yes\n",
    "endpoint = 'EPA'\n",
    "descriptor = 'Hmodel'\n",
    "algorithm = 'RF'\n",
    "name = f'{endpoint}_{algorithm}_{descriptor}'\n",
    "\n",
    "encoder_epa = joblib.load('../encoder_models/encoder_epa.joblib')\n",
    "\n",
    "# model\n",
    "clf = RandomForestClassifier(random_state =42, n_jobs=6,\n",
    "                              n_estimators = 500, min_samples_split = 2, min_samples_leaf=2,\n",
    "                              max_features = 'sqrt', max_depth=65, bootstrap= False)\n",
    "\n",
    "#input\n",
    "a, b,c,d,e = prepare_input(train_labels, train_Hfeatures, target = 'EPA_category', encoder = encoder_epa)\n",
    "\n",
    "# results\n",
    "MCM_mf,  MCM_oof, MCM_model, cv_score  = Classification_meta_features(clf, a, c, b, d, e,cv=10,n_jobs=1, \n",
    "                                                      col_names = [f'{name}-1', f'{name}-2', f'{name}-3', f'{name}-4'])\n",
    "# report the results\n",
    "report_clf_models(cv_score)\n",
    "\n",
    "# Save results\n",
    "np.save(f'../results/Hierarchical_models/{name}.npy', MCM_oof)\n",
    "joblib.dump(MCM_model, f'../models/Hierarchical_models/{name}.pkl')\n",
    "joblib.dump(cv_score, f'../results/Hierarchical_models/{name}_CVScore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.659 std: 0.013\n",
      "Balance Accuracy: 0.59 std: 0.014\n",
      "matthews_corrcoef: 0.458 std: 0.019\n",
      "f1_score: 0.648 std: 0.015\n",
      "AUROC: 0.709 std: 0.011\n",
      "CPU times: total: 57min 27s\n",
      "Wall time: 9min 41s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../results/Hierarchical_models/EPA_xgboost_Hmodel_CVScore']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#yes\n",
    "endpoint = 'EPA'\n",
    "descriptor = 'Hmodel'\n",
    "algorithm = 'xgboost'\n",
    "name = f'{endpoint}_{algorithm}_{descriptor}'\n",
    "\n",
    "encoder_epa = joblib.load('../encoder_models/encoder_epa.joblib')\n",
    "\n",
    "# model\n",
    "clf = XGBClassifier(random_state =123, n_jobs=6,\n",
    "                    subsample = 0.9, n_estimators = 500, min_child_weight=3,\n",
    "                    max_depth = 10, learning_rate=0.01, gamma= 0,\n",
    "                    colsample_bytree = 0.6)\n",
    "\n",
    "#input\n",
    "a, b,c,d,e = prepare_input(train_labels, train_Hfeatures, target = 'EPA_category', encoder = encoder_epa)\n",
    "\n",
    "# results\n",
    "MCM_mf,  MCM_oof, MCM_model, cv_score  = Classification_meta_features(clf, a, c, b, d, e,cv=10,n_jobs=1, \n",
    "                                                      col_names = [f'{name}-1', f'{name}-2', f'{name}-3', f'{name}-4'])\n",
    "# report the results\n",
    "report_clf_models(cv_score)\n",
    "\n",
    "# Save results\n",
    "np.save(f'../results/Hierarchical_models/{name}.npy', MCM_oof)\n",
    "joblib.dump(MCM_model, f'../models/Hierarchical_models/{name}.pkl')\n",
    "joblib.dump(cv_score, f'../results/Hierarchical_models/{name}_CVScore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.655 std: 0.013\n",
      "Balance Accuracy: 0.573 std: 0.011\n",
      "matthews_corrcoef: 0.447 std: 0.016\n",
      "f1_score: 0.639 std: 0.015\n",
      "AUROC: 0.699 std: 0.009\n",
      "CPU times: total: 1.02 s\n",
      "Wall time: 4.25 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../results/Hierarchical_models/EPA_knn_Hmodel_CVScore']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#yes\n",
    "endpoint = 'EPA'\n",
    "descriptor = 'Hmodel'\n",
    "algorithm = 'knn'\n",
    "name = f'{endpoint}_{algorithm}_{descriptor}'\n",
    "\n",
    "encoder_epa = joblib.load('../encoder_models/encoder_epa.joblib')\n",
    "\n",
    "# model\n",
    "clf = KNeighborsClassifier(n_neighbors = 55, weights = 'distance', p=1)\n",
    "\n",
    "#input\n",
    "a, b,c,d,e = prepare_input(train_labels, train_Hfeatures, target = 'EPA_category', encoder = encoder_epa)\n",
    "\n",
    "# results\n",
    "MCM_mf,  MCM_oof, MCM_model, cv_score  = Classification_meta_features(clf, a, c, b, d, e,cv=10,n_jobs=6, \n",
    "                                                      col_names = [f'{name}-1', f'{name}-2', f'{name}-3', f'{name}-4'])\n",
    "# report the results\n",
    "report_clf_models(cv_score)\n",
    "\n",
    "# Save results\n",
    "np.save(f'../results/Hierarchical_models/{name}.npy', MCM_oof)\n",
    "joblib.dump(MCM_model, f'../models/Hierarchical_models/{name}.pkl')\n",
    "joblib.dump(cv_score, f'../results/Hierarchical_models/{name}_CVScore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.65 std: 0.012\n",
      "Balance Accuracy: 0.571 std: 0.011\n",
      "matthews_corrcoef: 0.441 std: 0.017\n",
      "f1_score: 0.636 std: 0.014\n",
      "AUROC: 0.698 std: 0.01\n",
      "CPU times: total: 16.1 s\n",
      "Wall time: 2min 16s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../results/Hierarchical_models/EPA_SVM_Hmodel_CVScore']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#yes\n",
    "endpoint = 'EPA'\n",
    "descriptor = 'Hmodel'\n",
    "algorithm = 'SVM'\n",
    "name = f'{endpoint}_{algorithm}_{descriptor}'\n",
    "\n",
    "encoder_epa = joblib.load('../encoder_models/encoder_epa.joblib')\n",
    "\n",
    "# model\n",
    "clf = SVC(random_state=42, probability=True,\n",
    "          C = 0.1, kernel = 'linear')\n",
    "\n",
    "#input\n",
    "a, b,c,d,e = prepare_input(train_labels, train_Hfeatures, target = 'EPA_category', encoder = encoder_epa)\n",
    "\n",
    "# results\n",
    "MCM_mf,  MCM_oof, MCM_model, cv_score  = Classification_meta_features(clf, a, c, b, d, e,cv=10,n_jobs=6, \n",
    "                                                      col_names = [f'{name}-1', f'{name}-2', f'{name}-3', f'{name}-4'])\n",
    "# report the results\n",
    "report_clf_models(cv_score)\n",
    "\n",
    "# Save results\n",
    "np.save(f'../results/Hierarchical_models/{name}.npy', MCM_oof)\n",
    "joblib.dump(MCM_model, f'../models/Hierarchical_models/{name}.pkl')\n",
    "joblib.dump(cv_score, f'../results/Hierarchical_models/{name}_CVScore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Endpoint 3: LD50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.549 std: 0.024\n",
      "R2: 0.629 std: 0.029\n",
      "MAE: 0.398 std: 0.019\n",
      "MSE: 0.302 std: 0.027\n",
      "CPU times: total: 36min 43s\n",
      "Wall time: 6min 21s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../results/Hierarchical_models/LD50_RF_Hmodel_CVScore']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#yes\n",
    "endpoint = 'LD50'\n",
    "descriptor = 'Hmodel'\n",
    "algorithm = 'RF'\n",
    "name = f'{endpoint}_{algorithm}_{descriptor}'\n",
    "\n",
    "# model\n",
    "rf_reg = RandomForestRegressor(random_state =42, n_jobs=6,\n",
    "                              n_estimators = 1500, min_samples_split = 5, min_samples_leaf=4,\n",
    "                              max_features = 'sqrt', max_depth=80, bootstrap= False)\n",
    "\n",
    "#input\n",
    "a, b,c,d,e = prepare_input(train_labels, train_Hfeatures, target = 'logLD50_mmolkg')\n",
    "\n",
    "# results\n",
    "RM_mf, RM_oof, RM_model, cv_score = Regression_meta_features(rf_reg, a, c, b, \n",
    "                                                       d, e,cv=10, n_jobs = 1, col_names = [f'{name}'])\n",
    "# report the results\n",
    "report_cv_reg_models(cv_score)\n",
    "\n",
    "# Save results\n",
    "np.save(f'../results/Hierarchical_models/{name}.npy', RM_oof)\n",
    "joblib.dump(RM_model, f'../models/Hierarchical_models/{name}.pkl')\n",
    "joblib.dump(cv_score, f'../results/Hierarchical_models/{name}_CVScore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.551 std: 0.026\n",
      "R2: 0.627 std: 0.031\n",
      "MAE: 0.399 std: 0.02\n",
      "MSE: 0.305 std: 0.029\n",
      "CPU times: total: 14min 8s\n",
      "Wall time: 2min 23s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../results/Hierarchical_models/LD50_xgboost_Hmodel_CVScore']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#yes\n",
    "endpoint = 'LD50'\n",
    "descriptor = 'Hmodel'\n",
    "algorithm = 'xgboost'\n",
    "name = f'{endpoint}_{algorithm}_{descriptor}'\n",
    "\n",
    "# model\n",
    "reg = XGBRegressor(random_state =123, n_jobs=6, objective ='reg:squarederror',\n",
    "                    subsample = 0.6, n_estimators = 1500, min_child_weight=1,\n",
    "                    max_depth = 10, learning_rate=0.01, gamma= 1,\n",
    "                    colsample_bytree = 0.9)\n",
    "\n",
    "#input\n",
    "a, b,c,d,e = prepare_input(train_labels, train_Hfeatures, target = 'logLD50_mmolkg')\n",
    "\n",
    "# results\n",
    "RM_mf, RM_oof, RM_model, cv_score = Regression_meta_features(reg, a, c, b, \n",
    "                                                       d, e,cv=10, n_jobs = 1, col_names = [f'{name}'])\n",
    "# report the results\n",
    "report_cv_reg_models(cv_score)\n",
    "\n",
    "# Save results\n",
    "np.save(f'../results/Hierarchical_models/{name}.npy', RM_oof)\n",
    "joblib.dump(RM_model, f'../models/Hierarchical_models/{name}.pkl')\n",
    "joblib.dump(cv_score, f'../results/Hierarchical_models/{name}_CVScore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.561 std: 0.025\n",
      "R2: 0.613 std: 0.03\n",
      "MAE: 0.408 std: 0.018\n",
      "MSE: 0.316 std: 0.028\n",
      "CPU times: total: 1.67 s\n",
      "Wall time: 3.23 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../results/Hierarchical_models/LD50_knn_Hmodel_CVScore']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#yes\n",
    "endpoint = 'LD50'\n",
    "descriptor = 'Hmodel'\n",
    "algorithm = 'knn'\n",
    "name = f'{endpoint}_{algorithm}_{descriptor}'\n",
    "\n",
    "# model\n",
    "reg = KNeighborsRegressor(p = 2, n_neighbors = 45, weights = 'distance')\n",
    "\n",
    "#input\n",
    "a, b,c,d,e = prepare_input(train_labels, train_Hfeatures, target = 'logLD50_mmolkg')\n",
    "\n",
    "# results\n",
    "RM_mf, RM_oof, RM_model, cv_score = Regression_meta_features(reg, a, c, b, \n",
    "                                                       d, e,cv=10, n_jobs = 6, col_names = [f'{name}'])\n",
    "# report the results\n",
    "report_cv_reg_models(cv_score)\n",
    "\n",
    "# Save results\n",
    "np.save(f'../results/Hierarchical_models/{name}.npy', RM_oof)\n",
    "joblib.dump(RM_model, f'../models/Hierarchical_models/{name}.pkl')\n",
    "joblib.dump(cv_score, f'../results/Hierarchical_models/{name}_CVScore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.553 std: 0.026\n",
      "R2: 0.625 std: 0.03\n",
      "MAE: 0.398 std: 0.019\n",
      "MSE: 0.306 std: 0.029\n",
      "CPU times: total: 2.89 s\n",
      "Wall time: 12.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../results/Hierarchical_models/LD50_SVM_Hmodel_CVScore']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#yes\n",
    "endpoint = 'LD50'\n",
    "descriptor = 'Hmodel'\n",
    "algorithm = 'SVM'\n",
    "name = f'{endpoint}_{algorithm}_{descriptor}'\n",
    "\n",
    "# model\n",
    "reg = SVR(C = 1, gamma = 0.01, kernel = 'rbf')\n",
    "\n",
    "#input\n",
    "a, b,c,d,e = prepare_input(train_labels, train_Hfeatures, target = 'logLD50_mmolkg')\n",
    "\n",
    "# results\n",
    "RM_mf, RM_oof, RM_model, cv_score = Regression_meta_features(reg, a, c, b, \n",
    "                                                       d, e,cv=10, n_jobs = 6, col_names = [f'{name}'])\n",
    "# report the results\n",
    "report_cv_reg_models(cv_score)\n",
    "\n",
    "# Save results\n",
    "np.save(f'../results/Hierarchical_models/{name}.npy', RM_oof)\n",
    "joblib.dump(RM_model, f'../models/Hierarchical_models/{name}.pkl')\n",
    "joblib.dump(cv_score, f'../results/Hierarchical_models/{name}_CVScore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the predictrions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2849, 100)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_Hfeatures = pd.read_csv('../data/Hmodel_features_combined/test_Hfeatures.csv', index_col = 'CASRN')\n",
    "test_Hfeatures.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toxic_RF_Hmodel: computing....\n",
      "Toxic_RF_Hmodel: saved\n",
      "Toxic_SVM_Hmodel: computing....\n",
      "Toxic_SVM_Hmodel: saved\n",
      "Toxic_knn_Hmodel: computing....\n",
      "Toxic_knn_Hmodel: saved\n",
      "Toxic_xgboost_Hmodel: computing....\n",
      "Toxic_xgboost_Hmodel: saved\n",
      "EPA_RF_Hmodel: computing....\n",
      "EPA_RF_Hmodel: saved\n",
      "EPA_SVM_Hmodel: computing....\n",
      "EPA_SVM_Hmodel: saved\n",
      "EPA_knn_Hmodel: computing....\n",
      "EPA_knn_Hmodel: saved\n",
      "EPA_xgboost_Hmodel: computing....\n",
      "EPA_xgboost_Hmodel: saved\n",
      "LD50_RF_Hmodel: computing....\n",
      "LD50_RF_Hmodel: saved\n",
      "LD50_SVM_Hmodel: computing....\n",
      "LD50_SVM_Hmodel: saved\n",
      "LD50_knn_Hmodel: computing....\n",
      "LD50_knn_Hmodel: saved\n",
      "LD50_xgboost_Hmodel: computing....\n",
      "LD50_xgboost_Hmodel: saved\n",
      "CPU times: total: 17.1 s\n",
      "Wall time: 7.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "index = test_Hfeatures.index\n",
    "\n",
    "model_path = '../models/Hierarchical_models/'\n",
    "result_path = '../results/Hierarchical_testset_preds/'\n",
    "\n",
    "endpoints = ['Toxic', 'EPA', 'LD50']\n",
    "descriptors = ['Hmodel']\n",
    "algorithms = ['RF', 'SVM', 'knn', 'xgboost']\n",
    "\n",
    "feature = test_Hfeatures.values.astype('float32')\n",
    "\n",
    "for e in endpoints:\n",
    "    for d in descriptors:\n",
    "        for a in algorithms:\n",
    "            name = f'{e}_{a}_{d}'\n",
    "            print(f'{name}: computing....')\n",
    "            model = joblib.load(f'{model_path}{name}.pkl')\n",
    "            \n",
    "            if e == 'Toxic':\n",
    "                predictions = model.predict_proba(feature)\n",
    "                df = pd.DataFrame(predictions, columns=[f'{name}-0', f'{name}-1'],index = index)\n",
    "                df.to_csv(f'{result_path}{name}.csv')\n",
    "\n",
    "                print(f'{name}: saved')\n",
    "            if e == 'EPA':\n",
    "                predictions = model.predict_proba(feature)\n",
    "                df = pd.DataFrame(predictions, columns=[f'{name}-1', f'{name}-2', f'{name}-3', f'{name}-4'], index = index)\n",
    "                df.to_csv(f'{result_path}{name}.csv')\n",
    "\n",
    "                print(f'{name}: saved')\n",
    "            if e == 'LD50':\n",
    "                predictions = model.predict(feature)\n",
    "                df = pd.DataFrame(predictions, columns=[f'{name}'],index = index)\n",
    "                df.to_csv(f'{result_path}{name}.csv')\n",
    "                print(f'{name}: saved') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
